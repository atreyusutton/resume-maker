const express = require('express');
const cors = require('cors');
const fs = require('fs');
const path = require('path');
require('dotenv').config();
const OpenAI = require('openai');

const app = express();
const PORT = process.env.PORT || 5001;

app.use(cors());
app.use(express.json({ limit: '2mb' }));

// Keep in sync with front-end mapping
const sectionTypes = {
  personal: 'Personal Information',
  objective: 'Objective',
  experience: 'Experience',
  skills: 'Skills',
  education: 'Education',
  projects: 'Projects',
  other: 'Other'
};

app.post('/api/save-resume', (req, res) => {
  try {
    const resumeData = req.body;
    if (!resumeData || typeof resumeData !== 'object') {
      return res.status(400).json({ error: 'Invalid resume data payload' });
    }

    const targetPath = path.join(__dirname, 'src', 'data', 'resumeData.js');

    const fileHeader = `// This file is auto-generated by the local API (server.js)\n` +
      `// Do not edit by hand; use the app and click \"Save to Code\".\n`;

    const fileContents = `${fileHeader}\n` +
      `export const initialResumeData = ${JSON.stringify(resumeData, null, 2)};\n\n` +
      `export const sectionTypes = ${JSON.stringify(sectionTypes, null, 2)};\n`;

    fs.writeFileSync(targetPath, fileContents, 'utf8');
    return res.json({ ok: true });
  } catch (error) {
    console.error('Error saving resume data to file:', error);
    return res.status(500).json({ error: 'Failed to save resume data' });
  }
});

app.post('/api/save-cover-letter', (req, res) => {
  try {
    const { content } = req.body || {};
    if (typeof content !== 'string') {
      return res.status(400).json({ error: 'Invalid cover letter content payload' });
    }

    const targetPath = path.join(__dirname, 'src', 'data', 'coverLetterData.js');

    const fileHeader = `// This file is auto-generated by the local API (server.js)\n` +
      `// Do not edit by hand; use the app and click \"Save to Code\".\n`;

    const fileContents = `${fileHeader}\n` +
      `export const initialCoverLetter = ${JSON.stringify(content, null, 2)};\n`;

    fs.writeFileSync(targetPath, fileContents, 'utf8');
    return res.json({ ok: true });
  } catch (error) {
    console.error('Error saving cover letter to file:', error);
    return res.status(500).json({ error: 'Failed to save cover letter' });
  }
});

app.listen(PORT, () => {
  console.log(`Local API server listening on http://localhost:${PORT}`);
});

// ========== AI Optimization Endpoint ==========
const openai = new OpenAI({ apiKey: process.env.OPENAI_API_KEY });

app.post('/api/optimize-application', async (req, res) => {
  try {
    if (!process.env.OPENAI_API_KEY) {
      return res.status(500).json({ error: 'Missing OPENAI_API_KEY in environment' });
    }

    const { jobText, resumeData } = req.body || {};
    if (typeof jobText !== 'string' || !jobText.trim()) {
      return res.status(400).json({ error: 'Invalid jobText' });
    }
    if (!resumeData || typeof resumeData !== 'object') {
      return res.status(400).json({ error: 'Invalid resumeData' });
    }

    const system = `You are an expert resume and cover letter writer.

Goals:
1) Extract at least 20 relevant keywords from the job description and incorporate as many as possible naturally into the outputs.
2) Generate a job-specific Objective using the keywords.
3) For EVERY experience entry, rewrite the bullets to align to the listing (no fabrications; only rephrase/condense/align).
4) For EVERY project entry, rewrite into bullet points and suggest aligned skillsUsed (do not invent technologies not plausibly inferred; align with listing and original project context).
5) For EVERY additional information (other) item, rewrite content to fit the listing (no fabrications).
6) Provide a company-specific missing skills list (capitalized items) for a new category named "Skills for {company}" indicating skills likely missing given the job description. Do not remove or modify existing skill categories in this response.

Strictness:
- Do NOT add or remove experience/projects/education/other items; provide rewrites mapped by existing IDs only.
- Maintain factual accuracy from the provided resume content.
- Output STRICT JSON matching the provided schema.`;

    const schema = {
      type: 'object',
      properties: {
        updatedObjective: { type: 'string' },
        updatedExperienceBullets: {
          type: 'object',
          description: 'Map of experience id to optimized bullet strings array',
          additionalProperties: {
            type: 'array',
            items: { type: 'string' }
          }
        },
        updatedProjects: {
          type: 'object',
          description: 'Map of project id to { descriptionBullets: string[], skillsUsed: string[] }',
          additionalProperties: {
            type: 'object',
            properties: {
              descriptionBullets: { type: 'array', items: { type: 'string' } },
              skillsUsed: { type: 'array', items: { type: 'string' } }
            },
            required: ['descriptionBullets', 'skillsUsed']
          }
        },
        updatedOther: {
          type: 'object',
          description: 'Map of other-section item id to rewritten content string (may be bullet list)',
          additionalProperties: { type: 'string' }
        },
        companyName: { type: 'string' },
        missingSkills: { type: 'array', items: { type: 'string' } },
        coverLetter: { type: 'string' }
      },
      required: ['updatedObjective', 'updatedExperienceBullets', 'updatedProjects', 'updatedOther', 'companyName', 'missingSkills', 'coverLetter']
    };

    const user = {
      jobText,
      resumeSummary: {
        personal: resumeData.personal?.data || {},
        objective: resumeData.objective?.data || {},
        experience: (resumeData.experience?.data || []).map((exp) => ({
          id: exp.id,
          job: exp.job,
          company: exp.company,
          bullets: (exp.bullets || []).map((b) => b.text)
        })),
        projects: (resumeData.projects?.data || []).map((p) => ({
          id: p.id,
          title: p.title,
          skillsUsed: p.skillsUsed || [],
          description: p.description || ''
        })),
        other: (resumeData.other?.data || []).map((o) => ({
          id: o.id,
          title: o.title,
          content: o.content || ''
        })),
        skills: resumeData.skills?.data || []
      }
    };

    // ========== Local keyword extraction and suggestions across ALL sections ==========
    const STOPWORDS = new Set([
      'and','or','the','a','an','to','of','in','for','with','on','at','by','from','as','is','are','be','this','that','these','those','you','your','we','our','us','they','their','it','its','will','shall','can','may','must','should','include','including','etc','ability','experience','years','year','work','working','team','teams','using','use','used','plus','preferred','required','requirements','responsibilities','responsibility','about'
    ]);

    const COMMON_TECH = [
      'javascript','typescript','react','node','node.js','nodejs','python','java','go','ruby','php','c++','c#','aws','gcp','azure','sql','nosql','postgres','mysql','mongodb','redis','docker','kubernetes','k8s','graphql','rest','html','css','sass','tailwind','storybook','next.js','nextjs','vite','webpack','babel','jest','cypress','playwright','git','github','gitlab','ci','cd','devops','linux','macos','ios','android','swift','kotlin','firebase','supabase','prisma','sequelize','django','flask','fastapi','spring','spring boot','laravel','rails','express','s3','ec2','lambda','cloudfront'
    ];

    function extractKeywords(text) {
      const normalized = (text || '')
        .replace(/\+/g, ' ')
        .replace(/\//g, ' ')
        .toLowerCase();
      const rawTokens = normalized.match(/[a-z0-9.#+\-]+/g) || [];
      const tokens = rawTokens
        .map(t => t.replace(/^[^a-z0-9]+|[^a-z0-9]+$/g, ''))
        .filter(Boolean)
        .filter(t => t.length >= 3 && !STOPWORDS.has(t));
      const set = new Set(tokens);
      // also add canonical forms of common tech
      COMMON_TECH.forEach(t => {
        if (normalized.includes(t)) set.add(t);
      });
      return Array.from(set);
    }

    const jobKeywords = extractKeywords(jobText);

    function extractJobTitleFromText(text) {
      const lines = (text || '').split(/\r?\n/).map(l => l.trim()).filter(Boolean);
      // Named field patterns
      for (const line of lines) {
        const m = line.match(/^(?:job\s*title|title|position)\s*[:\-]\s*(.+)$/i);
        if (m && m[1]) return m[1].replace(/\s*\(.+\)$/, '').trim();
      }
      // Look for common role words
      const ROLE_HINTS = /(engineer|developer|designer|manager|analyst|scientist|architect|lead|principal|director|specialist|consultant)/i;
      for (const line of lines.slice(0, 10)) {
        if (ROLE_HINTS.test(line) && line.length <= 120) {
          // Remove location/company if separated by - or |
          return line.split(/\s[\-|\u2013\u2014]\s|\|/)[0].trim();
        }
      }
      // Fallback to first capitalized phrase from keywords
      const guess = jobKeywords.find(k => /[a-z]/.test(k));
      return guess ? guess.charAt(0).toUpperCase() + guess.slice(1) : 'Target Role';
    }
    const parsedJobTitle = extractJobTitleFromText(jobText);

    function textContainsAny(text, keywords) {
      if (!text) return false;
      const lower = text.toLowerCase();
      return keywords.some(k => lower.includes(k));
    }

    // Experience suggestions
    const experienceVisibility = {};
    const bulletVisibility = {};
    (resumeData.experience?.data || []).forEach(exp => {
      const expText = `${exp.job || ''} ${exp.company || ''} ${exp.location || ''}`;
      const bulletMatches = (exp.bullets || []).map(b => {
        const match = textContainsAny(b.text || '', jobKeywords);
        bulletVisibility[b.id] = match;
        return match;
      });
      const anyMatch = textContainsAny(expText, jobKeywords) || bulletMatches.some(Boolean);
      experienceVisibility[exp.id] = !!anyMatch;
    });

    // Education suggestions
    const educationVisibility = {};
    (resumeData.education?.data || []).forEach(edu => {
      const eduText = `${edu.school || ''} ${edu.degree || ''}`;
      educationVisibility[edu.id] = textContainsAny(eduText, jobKeywords);
    });

    // Skills suggestions
    const skillsCategoryVisibility = {};
    const skillsAdditions = {};
    const existingSkillsSet = new Set();
    (resumeData.skills?.data || []).forEach(cat => {
      (cat.skills || []).forEach(s => existingSkillsSet.add((s || '').toLowerCase()));
      const hasMatch = (cat.skills || []).some(s => textContainsAny(s || '', jobKeywords));
      skillsCategoryVisibility[cat.id] = !!hasMatch;
      skillsAdditions[cat.id] = [];
    });
    const keywordsNotInSkills = jobKeywords
      .filter(k => !existingSkillsSet.has(k))
      .filter(k => /[a-z]/.test(k));
    const newSkillCategories = keywordsNotInSkills.length > 0 ? [
      { category: 'Suggested Keywords', skills: Array.from(new Set(keywordsNotInSkills)).slice(0, 15) }
    ] : [];

    // Projects suggestions
    const projectVisibility = {};
    (resumeData.projects?.data || []).forEach(proj => {
      const projText = `${proj.title || ''} ${(proj.skillsUsed || []).join(' ')} ${proj.description || ''}`;
      projectVisibility[proj.id] = textContainsAny(projText, jobKeywords);
    });
    const techKeywords = jobKeywords.filter(k => COMMON_TECH.includes(k));
    const domainKeywords = jobKeywords.filter(k => !COMMON_TECH.includes(k));
    const pick = (arr, n) => Array.from(new Set(arr)).slice(0, n);
    // Heuristic company name extraction
    function extractCompanyName(text) {
      const lines = (text || '').split(/\r?\n/).map(l => l.trim()).filter(Boolean);
      for (const line of lines.slice(0, 8)) {
        const m = line.match(/^(?:company|employer)\s*[:\-]\s*(.+)$/i);
        if (m && m[1]) return m[1].replace(/\s*\(.+\)$/, '').trim();
      }
      const atMatch = (text || '').match(/\b(?:at|with)\s+([A-Z][\w&.,\- ]{1,50})/);
      if (atMatch && atMatch[1]) return atMatch[1].trim();
      return 'Company';
    }
    const companyName = extractCompanyName(jobText);

    const response = await openai.chat.completions.create({
      model: 'gpt-4o-mini',
      response_format: { type: 'json_object' },
      messages: [
        { role: 'system', content: system },
        { role: 'user', content: `Return JSON strictly matching this JSON Schema: ${JSON.stringify(schema)}.\nInput: ${JSON.stringify(user)}` }
      ],
      temperature: 0.7
    });

    const content = response.choices?.[0]?.message?.content || '{}';
    let json;
    try {
      json = JSON.parse(content);
    } catch (e) {
      return res.status(500).json({ error: 'Model did not return valid JSON' });
    }

    const result = {
      ...json,
      keywordList: jobKeywords,
      parsedJobTitle,
      companyName
    };

    return res.json(result);
  } catch (error) {
    console.error('Error optimizing application:', error);
    const status = error?.status || 500;
    const code = error?.code || error?.error?.code;
    const message = error?.message || 'Failed to optimize application';
    return res.status(status).json({ error: message, code: code || 'server_error' });
  }
});


